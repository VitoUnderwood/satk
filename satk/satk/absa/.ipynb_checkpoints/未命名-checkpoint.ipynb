{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.tokenization_bert import BertTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers.modeling_bert import BertPreTrainedModel\n",
    "from transformers.modeling_bert import BertModel\n",
    "import math\n",
    "\n",
    "from utils.span import Span\n",
    "span = Span(n_best_size=13, max_span_length=20, top_K=13)\n",
    "\n",
    "class Feature:\n",
    "    def __init__(self, idx, input_ids, input_mask, segment_ids):\n",
    "        self.idx = idx\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "\n",
    "    @classmethod\n",
    "    def make_single(cls, idx, tokens, tokenizer, max_seq_length):\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "\n",
    "        assert len(tokens) <= max_seq_length\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "        segment_ids = [0] * len(input_ids)\n",
    "\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        return cls(idx, input_ids, input_mask, segment_ids)\n",
    "    \n",
    "    @classmethod\n",
    "    def make_double(cls, idx, tokens1, tokens2, tokenizer, max_seq_length):\n",
    "        tokens = ['[CLS]'] + tokens1 + ['[SEP]'] + tokens2 + ['[SEP]']\n",
    "\n",
    "        assert len(tokens) <= max_seq_length\n",
    "    \n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "        segment_ids = [0] * (len(tokens1) + 2) + [1] * (len(tokens2) + 1)\n",
    "\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        return cls(idx, input_ids, input_mask, segment_ids)\n",
    "\n",
    "def convert_feature_to_tensor(features):\n",
    "    all_idx = torch.tensor([f.idx for f in features], dtype=torch.long)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    return all_idx, all_input_ids, all_input_mask, all_segment_ids\n",
    "\n",
    "\n",
    "class SpanModel(nn.Module):\n",
    "    def __init__(self, hidden_size=768, n_span=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_span_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size+1, hidden_size+1),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_size+1, n_span) \n",
    "        )\n",
    "        self.qa_outputs = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 2)\n",
    "        )\n",
    "\n",
    "    def span_predict(self, sequence_output, attention_mask):\n",
    "        \"\"\"\n",
    "        sequence_ouptput: [B, L, H]\n",
    "        attention_mask: [B, L]\n",
    "        start_positions, end_positions: [B, L]\n",
    "        \"\"\"\n",
    "        logits = self.qa_outputs(sequence_output) - (1-attention_mask.unsqueeze(-1)) * 10000.        \n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        # [B, L]\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "        \n",
    "        return start_logits, end_logits\n",
    "\n",
    "    def n_predict(self, sequence_output, mask, start_logits, end_logits):\n",
    "        \"\"\"\n",
    "        sequence_output: [B, L, H]\n",
    "        mask: [B, L]\n",
    "        n_true: [B,]\n",
    "        start_logits, end_logits: [B, L]\n",
    "        \"\"\"\n",
    "        h_target1 = torch.max(sequence_output * mask.unsqueeze(-1), dim=1)[0]\n",
    "        h_target2 = torch.sum(F.relu(start_logits * mask), dim=-1, keepdim=True)\n",
    "        h_target3 = torch.sum(F.relu(end_logits * mask), dim=-1, keepdim=True)\n",
    "\n",
    "        h_target = torch.cat((h_target1, h_target2 + h_target3), dim=-1)\n",
    "\n",
    "        n_pred = self.n_span_layer(h_target)\n",
    "        n_pred = n_pred.argmax(dim=-1) + 1\n",
    "        return n_pred\n",
    "\n",
    "\n",
    "class SpanExtraction(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.bert = BertModel(config)\n",
    "        self.span_model = SpanModel(hidden_size=768, n_span=4)\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "    def predict(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        seq_mask = attention_mask - token_type_ids\n",
    "        start_logits, end_logits = self.span_model.span_predict(\n",
    "            sequence_output, seq_mask)\n",
    "        \n",
    "        n_pred = self.span_model.n_predict(\n",
    "            sequence_output, seq_mask, start_logits, end_logits)\n",
    "\n",
    "        return start_logits, end_logits, n_pred\n",
    "\n",
    "\n",
    "class TOWE:\n",
    "    \"\"\"\n",
    "    1. self.init()\n",
    "    2. self.train(...)\n",
    "    3. cls.load(...)\n",
    "    \"\"\"\n",
    "    def __init__(self, ModelClass):\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        print('init_model')\n",
    "\n",
    "        self.model = ModelClass.from_pretrained('models')\n",
    "\n",
    "    def output_result(self, sentence, target):\n",
    "        tokens = tokenizer.tokenize(sentence)\n",
    "        target_tokens = tokenizer.tokenize(target)\n",
    "\n",
    "        feature = Feature.make_double(1, tokens, target_tokens, tokenizer, len(tokens) + len(target_tokens) + 3)\n",
    "        features = [feature]\n",
    "        _, input_ids, attention_mask, token_type_ids = convert_feature_to_tensor(features)\n",
    "\n",
    "        start_logits, end_logits, n_pred = self.model.predict(\n",
    "            input_ids.to(self.device), attention_mask.to(self.device), token_type_ids.to(self.device))\n",
    "        \n",
    "        y_pred = span.parse(start_logits[0].detach().cpu().numpy(), \n",
    "                            end_logits[0].detach().cpu().numpy(),\n",
    "                            pn=n_pred[0].detach().cpu().numpy())\n",
    "        opinion_words = []\n",
    "        print(f'句子:{tokens}中评价对象{target_tokens}对应的观点评价词：')\n",
    "        for s, e in y_pred:\n",
    "            print(s-1,e-1, tokens[s-1:e-1])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ------------------------------------------------#    \n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # -------------------- main ----------------------#\n",
    "    srt = TOWE(SpanExtraction)\n",
    "\n",
    "\n",
    "    sentence = \"Not the biggest portions but adequate .\"\n",
    "    target = 'portions'\n",
    "    srt.output_result(sentence, target)\n",
    "    sentence = \"It has great sushi and even better service .\"\n",
    "    target = 'sushi'\n",
    "    srt.output_result(sentence, target)\n",
    "    sentence = \"I complained to the manager , but he was not even apologetic .\"\n",
    "    target = 'manager'\n",
    "    while True:\n",
    "        srt.output_result(sentence, target)\n",
    "        sentence = input('sentence: ')\n",
    "        if sentence == '':\n",
    "            break\n",
    "        target = input('target: ')\n",
    "    # ------------------------------------------------#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import satk.absa.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /Users/vito/models were not used when initializing SpanExtraction: ['span_model.att_merge.query_', 'span_model.att_merge.hidden_layer.weight', 'span_model.att_merge.hidden_layer.bias']\n",
      "- This IS expected if you are initializing SpanExtraction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing SpanExtraction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "a = satk.absa.api.Absa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子:['the', 'food', 'was', 'lou', '##sy', '-', 'too', 'sweet', 'or', 'too', 'salty', 'and', 'the', 'portions', 'tiny']中评价对象['food']对应的观点评价词：\n",
      "6 8 ['too', 'sweet']\n"
     ]
    }
   ],
   "source": [
    "a(\"The food was lousy - too sweet or too salty and the portions tiny\", \"food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('ml': conda)",
   "language": "python",
   "name": "python37764bitmlconda34f4c0e8019f49848bc5a3e96f43aeac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
